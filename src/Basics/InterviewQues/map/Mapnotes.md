âœ… HashMap Internals â€” Detailed Step-By-Step (5 Points)
1ï¸âƒ£ Index Calculation (How HashMap decides the bucket)

Whenever you insert or get a key:

Step 1 â€” Compute hash

Java mixes the keyâ€™s hashCode using:

hash = h ^ (h >>> 16)


This reduces collisions.

Step 2 â€” Choose bucket
index = hash & (capacity - 1)


Why?

Capacity is always a power of 2 â†’ 16, 32, 64 â€¦

capacity - 1 becomes a mask of all 1s

& (bitwise AND) is faster than % (modulus)

Gives uniform distribution

This ensures the index is always between 0 and (capacity - 1).

2ï¸âƒ£ Insertion & Collision Handling (What happens inside a bucket)

After computing the index:

Case A â€” Bucket is empty

â†’ Directly store node (key, value, hash, next)

Case B â€” Bucket already contains entries (Collision)

HashMap compares:

Hash value

If equal â†’ equals() on key

If key matches â†’ update value
If key different â†’ append node

Collision structures:

LinkedList â†’ when bucket size < 8

Red-Black Tree â†’ when bucket size â‰¥ 8 (and table size â‰¥ 64)

This makes worst-case lookup O(log n) instead of O(n).

3ï¸âƒ£ Load Factor, Capacity & Threshold (When HashMap decides to resize)

HashMap keeps track of how full it is.

Capacity â†’ number of buckets (default 16)

Load factor â†’ how full buckets can get before resize (default 0.75)

Threshold = capacity Ã— load factor

Example:

capacity = 16
load factor = 0.75
threshold = 16 Ã— 0.75 = 12

Resize happens when:
total entries > threshold


â— Important:
Resize depends on total number of entries, NOT on collisions or bucket sizes.

4ï¸âƒ£ Resizing & Rehashing (What happens during growth)

When entries exceed threshold:

Step 1 â€” capacity doubles

16 â†’ 32 â†’ 64 â†’ 128 â†’ â€¦

Step 2 â€” threshold updates

New threshold = new capacity Ã— load factor

Step 3 â€” Rehashing

Every key is re-evaluated:

newIndex = hash & (newCapacity - 1)


This redistributes nodes across the new table to reduce collisions.

This ensures HashMap maintains O(1) average performance.

5ï¸âƒ£ Treeification (Making collision chains faster â€” Java 8+)

When one bucket gets too many elements:

Treeification rules:

HashMap converts a bucket from LinkedList â†’ Red-Black Tree if:

bucket size â‰¥ 8
and
table size â‰¥ 64

Why table â‰¥ 64?

For small tables, long chains occur naturally â†’ resize fixes it better

Tree nodes cost more memory â†’ avoid overhead on small maps

Result:

Tree buckets provide:

O(log n) lookup

Faster gets/puts for heavily collided keys

More stable worst-case performance

ğŸ¯ Final 5-Point Flow (Use this in interviews)

Index Calculation:
HashMap computes a mixed hash and uses hash & (capacity âˆ’ 1) to select a bucketâ€”fast, uniform, power-of-two optimization.

Insertion & Collision Handling:
Keys go into buckets as Nodes. If bucket is empty â†’ insert.
If collision â†’ compare keys â†’ add to linked list or update existing node.

Load Factor & Threshold:
HashMap resizes when total entries exceed capacity Ã— load factor (default threshold: 12 for capacity 16).

Resizing & Rehashing:
When size grows beyond threshold, capacity doubles and all entries are rehashed into new buckets.

Treeification:
Buckets with â‰¥ 8 nodes (and table â‰¥ 64) become Red-Black Trees to reduce lookup time from O(n) to O(log n).


https://medium.com/@kundansingh0619/introduction-to-maps-in-java-internal-working-of-hashmap-67129b94c3b5